{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6A5eDQte5MGl"
   },
   "source": [
    "# **StackOverflow Top10 tags**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vhkQ8tQl5eKO"
   },
   "source": [
    "The aim is here to build a model to predict the tag associated with the text. (Here we will build a model for the top 10 tags only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Fc9Flu05w5w"
   },
   "outputs": [],
   "source": [
    " # Importing data sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oH0vhFF4UEh2"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q PyDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "ackY96iNu4FJ",
    "outputId": "a6ad33e2-2521-4c04-bb5f-bd2b3c7b111a"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eO__yTDOvFcn"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QbTu2iVQvlHd"
   },
   "outputs": [],
   "source": [
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iRoaEERyv0J7"
   },
   "outputs": [],
   "source": [
    "downloaded= drive.CreateFile({'id': '1h4Xd0WgRd14Nv0PRVypkqOt11hNteCnS'})\n",
    "downloaded.GetContentFile('stacksample.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "J5dZetsuwsol",
    "outputId": "482a506f-2bd5-46a6-b84e-e1e7fc97bc50"
   },
   "outputs": [],
   "source": [
    "!unzip stacksample.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WDqvwPk35oh"
   },
   "outputs": [],
   "source": [
    "#Importing required packages.\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wib_Uiwj4A4t"
   },
   "outputs": [],
   "source": [
    "questions_data= pd.read_csv('Questions.csv', encoding='iso-8859-1')\n",
    "tags_data= pd.read_csv('Tags.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3R8bZq4D4W9q"
   },
   "outputs": [],
   "source": [
    "#filtering the top_10 most associated tags from the entire dataset\n",
    "top_10= list(tags_data['Tag'].value_counts().head(10).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "id": "CMPBTtqu4_Y7",
    "outputId": "f83d7551-1d86-435c-fab0-6d99dfc944d7"
   },
   "outputs": [],
   "source": [
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whn478dD7MyU"
   },
   "outputs": [],
   "source": [
    "tags_data= tags_data[tags_data['Tag'].isin(top_10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jOtdiFFG6Fhh"
   },
   "outputs": [],
   "source": [
    "questions= pd.merge(tags_data, questions_data, how='inner', on=['Id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zKiSseV-CZt9"
   },
   "source": [
    "# **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnZDQFwM_zO7"
   },
   "outputs": [],
   "source": [
    "#Now, We will take only quesions with a score greater than 5. Will do that for 2 reasons:\n",
    "  #1- it will require less computational resources.\n",
    "  #2- The posts will probably be with a better quality and will be better tagged since they have lots of upvotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0ySYnpWZCwMw",
    "outputId": "6d1dc076-b9f6-4033-a268-1c3e2b8d3b27"
   },
   "outputs": [],
   "source": [
    "questions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vvMVuEPD_zMv"
   },
   "outputs": [],
   "source": [
    "questions= questions[questions['Score']>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_WffQbC2C_Ex",
    "outputId": "379cc962-5037-43c7-f2a4-428bd810336d"
   },
   "outputs": [],
   "source": [
    "questions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "IedcVnBO7YjM",
    "outputId": "42e8c28f-3c21-47c3-9cb8-71c9cd5b652c"
   },
   "outputs": [],
   "source": [
    "questions.head(3) #Here we see that [Id, OwnerUserId, CreationDate, ClosedDate, Score] will have no impact on predicting the tags;\n",
    "                  #hence we will not consider those for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KHSfy8fl7b3I"
   },
   "outputs": [],
   "source": [
    "questions= questions[['Tag','Title','Body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "9Ix818D67rOo",
    "outputId": "4953d407-a785-491d-dc1c-9793841d4605"
   },
   "outputs": [],
   "source": [
    "questions.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "colab_type": "code",
    "id": "IGTXkx1_71XW",
    "outputId": "8f2e3615-5e12-4e93-dcfc-e70cb66e3895"
   },
   "outputs": [],
   "source": [
    "# We will check whether we have any null values in the data set\n",
    "questions.isnull().mean(axis=0) #No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "9_szyjmmBZJV",
    "outputId": "f3c5a42e-695a-473c-bac5-3865ca67395c"
   },
   "outputs": [],
   "source": [
    "#We will check whether we have any duplicate values in the data set\n",
    "questions.duplicated().sum() #No duplicate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3EPG3UJfCqrT"
   },
   "outputs": [],
   "source": [
    "# #In the next two columns: Body and Title, we will use lots of text processing:\n",
    "#     Removing html format\n",
    "#     Lowering text\n",
    "#     Transforming abbreviations\n",
    "#     Removing punctuation (but keeping words like c# since it's the most popular tag)\n",
    "#     Lemmatizing words\n",
    "#     Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SKMw85NOEMCb"
   },
   "outputs": [],
   "source": [
    "#Importing the required package.\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qKThS_4KDc7x"
   },
   "outputs": [],
   "source": [
    "#Converting html to text in the BODY column.\n",
    "questions['Body']= questions['Body'].apply(lambda x: bs4.BeautifulSoup(x).get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2rV8wfdiWZhb"
   },
   "outputs": [],
   "source": [
    "#Converting html to text in the TITLE column.\n",
    "questions['Title']= questions['Title'].apply(lambda x: bs4.BeautifulSoup(x).get_text())\n",
    "questions['Title']= questions['Title'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WE8oeZpdD-W3"
   },
   "outputs": [],
   "source": [
    "#Defining a function to clean the texts.\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub(r\"\\'\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\'\\xa0\", \" \", text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qpiOLXpNEk_u"
   },
   "outputs": [],
   "source": [
    "#Cleaning the texts in the BODY column.\n",
    "questions['Body']= questions['Body'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vg7vpV8BWrhL"
   },
   "outputs": [],
   "source": [
    "#Cleaning the texts in the TITLE column.\n",
    "questions['Title']= questions['Title'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "colab_type": "code",
    "id": "fSM2KKMmEze_",
    "outputId": "e351bdda-8da1-4160-c54c-71875cbc6d95"
   },
   "outputs": [],
   "source": [
    "questions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbU7XVYkdHui"
   },
   "source": [
    "# **Model Builing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BxOIpFqXS26N"
   },
   "outputs": [],
   "source": [
    "#Importing the required packages.\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding, BatchNormalization, GRU, concatenate\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZiTvyoEAdGzq"
   },
   "outputs": [],
   "source": [
    "questions_train, questions_test= train_test_split(questions, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oc3zD2dleO8m"
   },
   "outputs": [],
   "source": [
    "x_train_t= questions_train['Title']\n",
    "x_train_b= questions_train['Body']\n",
    "y_train= pd.get_dummies(questions_train['Tag'])\n",
    "\n",
    "x_test_t= questions_test['Title']\n",
    "x_test_b= questions_test['Body']\n",
    "y_test= pd.get_dummies(questions_test['Tag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0sG_a2BFoUkf"
   },
   "source": [
    "***For Title...***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6hBM1jInnYvp",
    "outputId": "08abfbdd-0bc3-41a0-d2e1-8065d4da5ad4"
   },
   "outputs": [],
   "source": [
    "sent_lens_t=[]\n",
    "for sent in questions_train['Title']:\n",
    "  sent_lens_t.append(len(word_tokenize(sent)))\n",
    "\n",
    "max(sent_lens_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "M6i--5HXnYzC",
    "outputId": "6d7229c8-e44b-4a74-c299-0b2849d8eb44"
   },
   "outputs": [],
   "source": [
    "np.quantile(sent_lens_t,0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZFGMMhwyn_AI"
   },
   "outputs": [],
   "source": [
    "#As we see that 95& of the word has lenth of 17, hence we will set the max length to 17\n",
    "max_len_t=17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bu02FwsEoMX_"
   },
   "outputs": [],
   "source": [
    "tok_t= Tokenizer(char_level=False, split=' ')\n",
    "tok_t.fit_on_texts(x_train_t)\n",
    "sequences_train_t= tok_t.texts_to_sequences(x_train_t)\n",
    "sequences_test_t= tok_t. texts_to_sequences(x_test_t) #Applying same for Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "R5F5YpkIo-2f",
    "outputId": "119aad75-966d-46f5-b78b-e3e3f900ccde"
   },
   "outputs": [],
   "source": [
    "vocab_len_t= len(tok_t.index_word.keys()) #verifying vocabulory length.\n",
    "vocab_len_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BDjo21QepS4R"
   },
   "outputs": [],
   "source": [
    "sequences_matrix_train_t= sequence.pad_sequences(sequences_train_t, maxlen= max_len_t)\n",
    "sequences_matrix_test_t= sequence.pad_sequences(sequences_test_t, maxlen= max_len_t) #Applying the same for Test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "colab_type": "code",
    "id": "ceF-GOy9pSOe",
    "outputId": "7c62fd15-1978-4471-ba6b-85368fd974c9"
   },
   "outputs": [],
   "source": [
    "sequences_matrix_train_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "colab_type": "code",
    "id": "1JtfgBKRptYi",
    "outputId": "08fe9837-e579-4035-bf78-c5a409d06b60"
   },
   "outputs": [],
   "source": [
    "sequences_matrix_test_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "36fOdsHwp1F0"
   },
   "source": [
    "***For Body...***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8I2KQYHxpuiW",
    "outputId": "2bdf7add-43a8-4cfb-b9cf-450a2f804dde"
   },
   "outputs": [],
   "source": [
    "sent_lens_b=[]\n",
    "for sent in questions_train['Body']:\n",
    "  sent_lens_b.append(len(word_tokenize(sent)))\n",
    "\n",
    "max(sent_lens_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rbgtTVvMqOqp",
    "outputId": "e301c483-8d62-49c1-8a86-4599ed7b1267"
   },
   "outputs": [],
   "source": [
    "np.quantile(sent_lens_b, 0.92)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j7aXq2LXqTgs"
   },
   "outputs": [],
   "source": [
    "#As we see that 92% of the word has length of 495, hence we will set the max length to 500\n",
    "max_len_b=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HpdEIqxoqq1R"
   },
   "outputs": [],
   "source": [
    "tok_b= Tokenizer(char_level=False, split=' ')\n",
    "tok_b.fit_on_texts(x_train_b)\n",
    "sequences_train_b= tok_b.texts_to_sequences(x_train_b)\n",
    "sequences_test_b= tok_b.texts_to_sequences(x_test_b)  #Applying same for Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YfnbFLiprOPu",
    "outputId": "e11369c1-b012-40cf-b566-6169d21f6d3a"
   },
   "outputs": [],
   "source": [
    "vocab_len_b= len(tok_b.index_word.keys())      #verifying vocabulory length.\n",
    "vocab_len_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RUiE44UMr3lu"
   },
   "outputs": [],
   "source": [
    "sequences_matrix_train_b= sequence.pad_sequences(sequences_train_b, maxlen= max_len_b)\n",
    "sequences_matrix_test_b= sequence.pad_sequences(sequences_test_b, maxlen= max_len_b)     #Applying the same for Test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "colab_type": "code",
    "id": "CXUQOrA4sPKe",
    "outputId": "7316cc41-a11b-4ce4-d928-fe90addddaf7"
   },
   "outputs": [],
   "source": [
    "sequences_matrix_train_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "colab_type": "code",
    "id": "PV8dBIqesTZC",
    "outputId": "c2400625-3636-455c-86b6-ae0f457d5625"
   },
   "outputs": [],
   "source": [
    "sequences_matrix_test_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6ApVjQtk4WYU"
   },
   "source": [
    "Verifying the shapes of the matrices..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6fewvK5KsUk_",
    "outputId": "02b523e7-f1a7-4398-f3d2-0eea01fd2ab4"
   },
   "outputs": [],
   "source": [
    "sequences_matrix_train_t.shape, sequences_matrix_train_b.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "XVl89ewv3Fxm",
    "outputId": "8cf721a7-52f1-4c1a-a101-85e70a9d7e49"
   },
   "outputs": [],
   "source": [
    "sequences_matrix_test_t.shape, sequences_matrix_test_b.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "HHGrrEPa4k-Y",
    "outputId": "b5399417-1c00-4d4d-dc42-7145f70870da"
   },
   "outputs": [],
   "source": [
    "print(max_len_t)\n",
    "print(max_len_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErQ_rc_5shPv"
   },
   "outputs": [],
   "source": [
    "#Downloading the Embedding to use the pre-trained weights.. \n",
    "!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "XSBgTN8Gt6Wj",
    "outputId": "9a1ee749-4cd1-4cc5-db88-c95284684fec"
   },
   "outputs": [],
   "source": [
    "#unzipping it..\n",
    "!unzip glove.twitter.27B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ofoq6Db96sJw"
   },
   "outputs": [],
   "source": [
    "embeddings_index= {}\n",
    "f= open('glove.twitter.27B.200d.txt')\n",
    "for line in f:\n",
    "  values= line.split()\n",
    "  word= values[0]\n",
    "  coefs= np.asarray(values[1:], dtype='float32')\n",
    "  embeddings_index[word]= coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1NsCIS9g73qY"
   },
   "outputs": [],
   "source": [
    "embedding_matrix_t= np.zeros((len(tok_t.word_index)+1,200))\n",
    "for word, i in tok_t.word_index.items():\n",
    "  embedding_vector= embeddings_index.get(word)\n",
    "  if embedding_vector is not None:\n",
    "    #words not found in embedding index will all be set to zeros.\n",
    "    embedding_matrix_t[i]= embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8u__dNEO84nl"
   },
   "outputs": [],
   "source": [
    "embedding_matrix_b= np.zeros((len(tok_b.word_index)+1,200))\n",
    "for word, i in tok_b.word_index.items():\n",
    "  embedding_vector= embeddings_index.get(word)\n",
    "  if embedding_vector is not None:\n",
    "    #words not found in embedding index will all be set to zeros.\n",
    "    embedding_matrix_b[i]= embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22ilQ4G4t8Ez"
   },
   "source": [
    "# **Model Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ln_GiC0Ytuwt"
   },
   "outputs": [],
   "source": [
    "def RNN():\n",
    "  #Title only...\n",
    "  title_input= Input(shape=[max_len_t], name='title_input')\n",
    "  title_Embed= Embedding(vocab_len_t+1, 200, weights=[embedding_matrix_t], trainable=False, input_length= max_len_t, mask_zero=True, name='title_Embed') (title_input)\n",
    "  lstm_out_t= LSTM(100) (title_Embed)\n",
    "  #Auxiliary output to tune LSTM weights smoothly...\n",
    "  auxiliary_output= Dense(10, activation= 'sigmoid', name= 'auxiliary_output') (lstm_out_t)\n",
    "\n",
    "  #Body only...\n",
    "  body_input= Input(shape=[max_len_b], name='body_input')\n",
    "  body_Embed= Embedding(vocab_len_b+1, 200, weights=[embedding_matrix_b], trainable=False, input_length= max_len_b, mask_zero=True, name='body_Embed') (body_input)\n",
    "  lstm_out_b= LSTM(100) (body_Embed)\n",
    "  \n",
    "  #Combined with LSTM output...\n",
    "  com= concatenate([lstm_out_t, lstm_out_b])\n",
    "\n",
    "  #Now combined data is being fed to dense layers...\n",
    "  dense1= Dense(50, activation='relu') (com)\n",
    "  dp1= Dropout(0.3) (dense1)\n",
    "  bn= BatchNormalization() (dp1)\n",
    "  dense2= Dense(30, activation='relu') (bn)  \n",
    "  main_output= Dense(10, activation='sigmoid', name='main_output') (dense2)\n",
    "\n",
    "  model= Model(inputs=[title_input, body_input], outputs=[main_output, auxiliary_output])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 653
    },
    "colab_type": "code",
    "id": "8_H6xy_JzKOe",
    "outputId": "ee497820-a2b0-45f0-a379-84f54af12946"
   },
   "outputs": [],
   "source": [
    "model= RNN()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1CXiPFjizQGc"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss={'main_output':'categorical_crossentropy', 'auxiliary_output': 'categorical_crossentropy'}, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1me_A1yCVqe8"
   },
   "source": [
    "**Defining ModelCheckpoint to save our model every 10 epoch...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EmN7qcIKQEVw"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "\n",
    "output_folder= './stackoverflow_output'\n",
    "if not os.path.exists(output_folder):\n",
    "  os.makedirs(output_folder)\n",
    "\n",
    "filepath= output_folder+\"/weights-{epoch:02d}-accuracy-{main_output_acc:.4f}.h5\"\n",
    "checkpoint= ModelCheckpoint(filepath, verbose=1, monitor='main_output_acc',\n",
    "                            save_best_only=False,\n",
    "                            save_weights_only=True,\n",
    "                            mode='auto', period=10) #This will save the weights every 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ml9qtdelzuqo"
   },
   "outputs": [],
   "source": [
    "results= model.fit({'title_input': sequences_matrix_train_t, 'body_input': sequences_matrix_train_b},\n",
    "                   {'main_output': y_train, 'auxiliary_output': y_train},\n",
    "                   validation_data= [{'title_input': sequences_matrix_test_t, 'body_input': sequences_matrix_test_b},\n",
    "                                     {'main_output': y_test, 'auxiliary_output': y_test}],\n",
    "                   epochs= 80, batch_size= 1000, callbacks=[checkpoint]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bp_vEKj02zGy"
   },
   "outputs": [],
   "source": [
    "#Now load the saved model for prediction..\n",
    "model.load_weights('/content/stackoverflow_output/weights-30-accuracy-0.8252.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UGWcvdpZ0odk",
    "outputId": "9075ab4d-3450-492a-f079-c2f09cade199"
   },
   "outputs": [],
   "source": [
    "#Predicting the model..\n",
    "(predict_main, predict_auxiliary)= model.predict({'title_input': sequences_matrix_test_t, 'body_input': sequences_matrix_test_b}, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f_YvAf-GLOKf"
   },
   "outputs": [],
   "source": [
    "#Importing required packages...\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "b3Eh4-E1LYgR",
    "outputId": "6b3df846-28ca-4529-8cf7-8e62ce32eecb"
   },
   "outputs": [],
   "source": [
    "print(f1_score(y_test, predict_main>0.55, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "colab_type": "code",
    "id": "zfLSZJTR6N4o",
    "outputId": "09230ddf-f377-406c-aa19-af16f54ca392"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predict_main>0.55))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "zdd7o90rLYjj",
    "outputId": "c896cdd9-0a4a-4b70-ccba-ad7df6e241bd"
   },
   "outputs": [],
   "source": [
    "predict_main[24].round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "id": "1GIdSWp3LOOe",
    "outputId": "f244a0a1-c37f-430f-e178-ee0feaa36ba7"
   },
   "outputs": [],
   "source": [
    "top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "RUuruiRb60Yt",
    "outputId": "9103cb05-c209-4deb-ac65-18050ffc94b9"
   },
   "outputs": [],
   "source": [
    "predict_main[].round(decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tlUME43ZL_yn"
   },
   "outputs": [],
   "source": [
    "#Saving the model..\n",
    "model.save('./stackoverflow_tags_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vs6ejMBTOHJD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Tags_Predicting_Github_code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
